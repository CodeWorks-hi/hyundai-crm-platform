# +---------+
# | ê³ ê° ì„¼í„° - Google Gemma-2-9B-IT ëª¨ë¸ API í˜¸ì¶œ |
# +---------+

import json
import re
import streamlit as st
from huggingface_hub import InferenceClient

# ëª¨ë¸ ë° API ì„¤ì •
TEXT_MODEL_ID = "google/gemma-2-9b-it"
API_TOKEN = st.secrets.get("HUGGINGFACE_API_TOKEN")

# Q&A ë°ì´í„°ì…‹ (ê²€ìƒ‰ ê²°ê³¼ ê¸°ë°˜)
FAQS = [
        {
            "q": "â™»ï¸ ì¤‘ê³ ì°¨ ë³´ìƒ íŒë§¤ í”„ë¡œê·¸ë¨ì´ ìˆë‚˜ìš”?",
            "a": """**ì¤‘ê³ ì°¨ ë³´ìƒ íŒë§¤ ì œë„ ì•ˆë‚´**  
    - ê¸°ì¡´ ì°¨ëŸ‰ì„ íŒë§¤í•˜ê³  ìƒˆ ì°¨ë¡œ êµì²´ ì‹œ ì¶”ê°€ í˜œíƒ ì œê³µ  
    - ë³´ìƒ ê¸ˆì•¡ì€ ì°¨ëŸ‰ ì—°ì‹, ìƒíƒœ, ì£¼í–‰ ê±°ë¦¬ ë“± ê¸°ì¤€ì— ë”°ë¼ ì‚°ì •  
    - ì°¸ì—¬ ë°©ë²•:  
        â‘  ê³ ê° í¬í„¸ì—ì„œ [ë³´ìƒ íŒë§¤ ì‹ ì²­ì„œ] ì‘ì„±  
        â‘¡ ì „ë¬¸ ê°ì • í›„ ê²¬ì  ì•ˆë‚´  
        â‘¢ ì‹ ê·œ ì°¨ëŸ‰ ê³„ì•½ ì‹œ ë³´ìƒ ê¸ˆì•¡ ì°¨ê°  
    - ë³´ìƒ íŒë§¤ ì‹œ ìµœëŒ€ 50ë§Œì› ì¶”ê°€ ì§€ì› ì´ë²¤íŠ¸ ì§„í–‰ ì¤‘"""
        },
        {
            "q": "ğŸ’¸ ì°¨ëŸ‰ ìœ ì§€ë¹„ëŠ” ì–¼ë§ˆë‚˜ ë“œë‚˜ìš”?",
            "a": """**ìœ ì§€ë¹„ ê³„ì‚°ê¸° / ì›” ìš´ì˜ë¹„ ì‹œë®¬ë ˆì´í„°**  
    â–¶ [ê³ ê° í¬í„¸ > ê²½ì œ ì¸ì‚¬ì´íŠ¸] ë©”ë‰´ì—ì„œ ì œê³µ  

    - ì˜ˆìƒ ì—° ì£¼í–‰ê±°ë¦¬ ì…ë ¥ ì‹œ ì›” í‰ê·  ìœ ì§€ë¹„ ìë™ ê³„ì‚°  
    - í¬í•¨ í•­ëª©:  
        â–· ì—°ë£Œë¹„ / ì „ê¸°ì°¨ ì¶©ì „ë¹„  
        â–· ì •ê¸°ì ê²€ ë° ì •ë¹„ ë¹„ìš©  
        â–· ë³´í—˜ë£Œ / ì„¸ê¸ˆ / ì£¼ì°¨ë¹„  

    - ì˜ˆ: ì—° 15,000km ê¸°ì¤€  
        - ê°€ì†”ë¦° ì°¨ëŸ‰: ì›” ì•½ 35ë§Œì›  
        - EV ì°¨ëŸ‰: ì›” ì•½ 22ë§Œì›"""
        },
        {
            "q": "ğŸ’¬ ìƒë‹´ì‚¬ ì—°ê²° ì—†ì´ ì±„íŒ… ìƒë‹´ ê°€ëŠ¥í•œê°€ìš”?",
            "a": """**AI ì±—ë´‡ ê¸°ë°˜ ê³ ê°ì§€ì› ì„œë¹„ìŠ¤**  
    - [ê³ ê° í¬í„¸ > 1:1 ì±„íŒ…ìƒë‹´] ë©”ë‰´ì—ì„œ ì‚¬ìš© ê°€ëŠ¥ ì˜ˆì •  
    - ì±—ë´‡ìœ¼ë¡œ ê°€ëŠ¥í•œ ìƒë‹´ í•­ëª©:  
        â–· ì°¨ëŸ‰ ì¶”ì²œ / êµ¬ë§¤ í”„ë¡œì„¸ìŠ¤ ì•ˆë‚´  
        â–· ì •ë¹„ ì¼ì • ì¡°íšŒ ë° ì˜ˆì•½  
        â–· í¬ì¸íŠ¸ ì‚¬ìš© / ì”ì•¡ ì¡°íšŒ  
        â–· ê²½ì œ ì§€í‘œ ê¸°ë°˜ ì°¨ëŸ‰ ê°€ê²© ì‹œë®¬ë ˆì´ì…˜  

    - ì¶”í›„ OpenAI ê¸°ë°˜ ëŒ€í™”í˜• ì±—ë´‡ ì—°ë™ ì˜ˆì •"""
        },
        {
            "q": "ğŸ” ì°¨ëŸ‰ ì¬êµ¬ë§¤ ì‹œ ì–´ë–¤ í˜œíƒì´ ìˆë‚˜ìš”?",
            "a": """**ì¬êµ¬ë§¤ ê³ ê° ìš°ëŒ€ í”„ë¡œê·¸ë¨**  
    - ë™ì¼ ë¸Œëœë“œ ì°¨ëŸ‰ 2íšŒ ì´ìƒ êµ¬ë§¤ ê³ ê° ëŒ€ìƒ  
    - í˜œíƒ ì˜ˆì‹œ:  
        âœ“ ë³´ì¦ ì—°ì¥ + í”„ë¦¬ë¯¸ì—„ ì •ë¹„ ì¿ í°  
        âœ“ ì „ìš© ê³ ê° ë“±ê¸‰ ë¶€ì—¬ (Platinum+)  
        âœ“ ì‹œìŠ¹ê¶Œ/ì´ˆì²­ í–‰ì‚¬ ì œê³µ  
    - ìµœê·¼ 5ë…„ ì´ë‚´ ì°¨ëŸ‰ êµ¬ë§¤ ì´ë ¥ì´ ìˆëŠ” ê³ ê°ì€ ìë™ ì ìš©"""
        },
        {
            "q": "ğŸ“ ì—¬ëŸ¬ ë”œëŸ¬ ì¤‘ ì–´ë””ê°€ ê°€ì¥ ìœ ë¦¬í•œê°€ìš”?",
            "a": """**ë”œëŸ¬ì‚¬ ë¹„êµ íŒ**  
    - [ë§¤ì¥ ì°¾ê¸°] ë©”ë‰´ì—ì„œ ì§€ì—­ë³„ ë”œëŸ¬ í‰ê°€/ë¦¬ë·° í™•ì¸ ê°€ëŠ¥  
    - ë¹„êµ í•­ëª©:  
        âœ“ í‰ê·  ì¶œê³  ì†Œìš”ì¼  
        âœ“ ì‹œìŠ¹ ì°¨ëŸ‰ ë³´ìœ  ì—¬ë¶€  
        âœ“ í”„ë¡œëª¨ì…˜ ì§„í–‰ ë‚´ì—­  
        âœ“ ì„œë¹„ìŠ¤ ë§Œì¡±ë„ ì ìˆ˜  
    - ë”œëŸ¬ì‚¬ ë³„ ì¸ì„¼í‹°ë¸Œ/ì‚¬ì€í’ˆë„ ìƒì´í•˜ë‹ˆ ê¼¼ê¼¼íˆ í™•ì¸í•˜ì„¸ìš”!"""
        }
    ]
]

# ì…ë ¥/ì¶œë ¥ ì²˜ë¦¬ í•¨ìˆ˜
def clean_input(text: str) -> str:
    return re.sub(r"\b(í•´ì¤˜|ì•Œë ¤ì¤˜|ì„¤ëª…í•´ ì¤˜)\b", "", text, flags=re.IGNORECASE).strip()

def format_response(text: str) -> str:
    cleaned = re.sub(r'<[^>]+>', '', text)
    return re.sub(r'\n{3,}', '\n\n', cleaned)

# AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_gemma_response(user_input: str) -> str:
    if not API_TOKEN:
        return "âŒ API í† í°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
    
    try:
        # FAQ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = "\n".join([f"Q: {item['q']}\nA: {item['a']}" for item in FAQS])
        
        client = InferenceClient(model=TEXT_MODEL_ID, token=API_TOKEN)
        response = client.text_generation(
            prompt=f"""**[í˜„ëŒ€ìë™ì°¨ ê³ ê°ì§€ì› ì‹œìŠ¤í…œ]**
{context}

**ì‚¬ìš©ì ì§ˆë¬¸:** {user_input}
**AI ì–´ì‹œìŠ¤í„´íŠ¸:**""",
            max_new_tokens=1000,
            temperature=0.7,
            return_full_text=False
        )
        return format_response(response)
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# Streamlit UI ì»´í¬ë„ŒíŠ¸
def gemma_ui():
    st.markdown("#### ğŸ¤– GEMMA AI ê³ ê° ì§€ì›")
    st.markdown("""
    ì°¨ëŸ‰ êµ¬ë§¤ë¶€í„° ìœ ì§€ê´€ë¦¬ê¹Œì§€ ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€ë“œë¦½ë‹ˆë‹¤.  
    ì•„ë˜ ì…ë ¥ì°½ì— ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.
    """)
    
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì¤‘ê³ ì°¨ ë³´ìƒ íŒë§¤ í”„ë¡œê·¸ë¨ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?)",
        key="gemma_input"
    )
    
    # ì§ˆë¬¸ ì²˜ë¦¬
    if st.button("ì§ˆë¬¸ ì œì¶œ", key="gemma_submit"):
        if not user_input.strip():
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        with st.spinner("AI ë¶„ì„ ì¤‘..."):
            cleaned_input = clean_input(user_input)
            response = generate_gemma_response(cleaned_input)
            
            # ê²°ê³¼ í‘œì‹œ
            with st.expander("ğŸ’¬ AI ë‹µë³€ ë³´ê¸°", expanded=True):
                st.markdown(response)
                
            # FAQ ë§¤ì¹­ ì‹œ ì¶”ê°€ ì •ë³´ í‘œì‹œ
            if any(faq['q'] in user_input for faq in FAQS):
                st.image("https://example.com/faq_banner.jpg", width=300)
