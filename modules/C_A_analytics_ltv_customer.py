import streamlit as st
import pandas as pd
import joblib
import numpy as np
from sklearn.preprocessing import OneHotEncoder
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
import os
from io import BytesIO
from reportlab.pdfgen import canvas


@st.cache_data
def load_data():
    df_customer = pd.read_csv("data/customer_data.csv")
    df_export = pd.read_csv("data/export_customer_data.csv")
    df_domestic = pd.read_csv("data/domestic_customer_data.csv")
    df_list = pd.read_csv("data/customers.csv")  # íŒŒì¼ëª… ìˆ˜ì •ë¨
    return df_customer, df_export, df_domestic, df_list


def preprocess_and_train_model(df):
    df = df.drop(columns=["ì´ë¦„", "ì—°ë½ì²˜", "ë¸Œëœë“œ", "ëª¨ë¸ëª…", "ê³µì¥ëª…"], errors="ignore")

    df["ê³ ê° ë“±ê¸‰"] = np.random.choice(["VIP", "ì¼ë°˜", "ì‹ ê·œ"], size=len(df))
    df["ì°¨ëŸ‰ ìœ í˜•"] = np.random.choice(["ì„¸ë‹¨", "SUV", "í•´ì¹˜ë°±"], size=len(df))
    df["í• ë¶€ ì—¬ë¶€"] = np.random.choice([0, 1], size=len(df))
    df["êµ¬ë§¤ ê²½ë¡œ"] = np.random.choice([0, 1], size=len(df))
    df["ìµœê·¼ ê±°ë˜ ê¸ˆì•¡"] = np.random.randint(10000000, 40000000, size=len(df))
    df["ëˆ„ì  êµ¬ë§¤ ê¸ˆì•¡"] = df["ìµœê·¼ ê±°ë˜ ê¸ˆì•¡"] + np.random.randint(10000000, 30000000, size=len(df))
    df["í‰ê·  êµ¬ë§¤ ê¸ˆì•¡"] = (df["ìµœê·¼ ê±°ë˜ ê¸ˆì•¡"] + df["ëˆ„ì  êµ¬ë§¤ ê¸ˆì•¡"]) // 2
    df["ê³ ê° ì¶©ì„±ë„ ì§€ìˆ˜"] = np.round(np.random.uniform(0.5, 1.0, size=len(df)), 2)
    df["ê³ ê° í‰ìƒ ê°€ì¹˜"] = df["ëˆ„ì  êµ¬ë§¤ ê¸ˆì•¡"] * df["ê³ ê° ì¶©ì„±ë„ ì§€ìˆ˜"]

    features = [
        "ì„±ë³„", "ì—°ë ¹ëŒ€", "ê±°ì£¼ ì§€ì—­", "ê³ ê° ë“±ê¸‰", "ì°¨ëŸ‰ ìœ í˜•",
        "ì°¨ëŸ‰ êµ¬ë§¤ íšŸìˆ˜", "í• ë¶€ ì—¬ë¶€", "êµ¬ë§¤ ê²½ë¡œ",
        "ìµœê·¼ ê±°ë˜ ê¸ˆì•¡", "ëˆ„ì  êµ¬ë§¤ ê¸ˆì•¡", "í‰ê·  êµ¬ë§¤ ê¸ˆì•¡", "ê³ ê° ì¶©ì„±ë„ ì§€ìˆ˜"
    ]
    target = "ê³ ê° í‰ìƒ ê°€ì¹˜"
    categorical_cols = ["ì„±ë³„", "ì—°ë ¹ëŒ€", "ê±°ì£¼ ì§€ì—­", "ê³ ê° ë“±ê¸‰", "ì°¨ëŸ‰ ìœ í˜•"]

    encoder = OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    encoded = encoder.fit_transform(df[categorical_cols])
    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols))

    X = pd.concat([df.drop(columns=categorical_cols + [target]), encoded_df], axis=1)
    y = df[target]

    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

    model = XGBRegressor(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42)
    model.fit(X_train, y_train)

    os.makedirs("model", exist_ok=True)
    joblib.dump(model, "model/xgb_domestic_ltv_model.pkl")

    return model, df, X


def generate_pdf_report(df_top10):
    buffer = BytesIO()
    c = canvas.Canvas(buffer)
    c.setFont("Helvetica", 14)
    c.drawString(100, 800, "LTV ì˜ˆì¸¡ ë¦¬í¬íŠ¸ ìƒìœ„ ê³ ê° 10ëª…")

    y = 760
    for i, row in df_top10.iterrows():
        line = f"{row['ì—°ë ¹ëŒ€']} / {row['ê±°ì£¼ ì§€ì—­']} / ì˜ˆì¸¡ LTV: {row['ì˜ˆì¸¡ LTV']:,.0f}ì›"
        c.drawString(80, y, line)
        y -= 20
        if y < 100:
            break

    c.save()
    buffer.seek(0)
    return buffer


def ltv_customer_ui():
    st.title(" LTV ê³ ê° ê°€ì¹˜ ì˜ˆì¸¡ ë¶„ì„")

    df_customer, df_export, df_domestic, df_list = load_data()

    with st.spinner("ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì¤‘..."):
        model, df_with_pred, X = preprocess_and_train_model(df_domestic)
        df_with_pred["ì˜ˆì¸¡ LTV"] = model.predict(X)

    st.success("âœ… ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì™„ë£Œ")

    st.markdown("### ğŸ” ì˜ˆì¸¡ LTV ê¸°ì¤€ ìƒìœ„ ê³ ê° TOP 10")
    top10 = df_with_pred[["ì—°ë ¹ëŒ€", "ê±°ì£¼ ì§€ì—­", "ê³ ê° í‰ìƒ ê°€ì¹˜", "ì˜ˆì¸¡ LTV"]].sort_values("ì˜ˆì¸¡ LTV", ascending=False).head(10)
    st.dataframe(top10.style.format({'ì˜ˆì¸¡ LTV': '{:,.0f}ì›'}), height=400)

    st.markdown("### ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ")
    pdf_buffer = generate_pdf_report(top10)
    st.download_button(
        label="ğŸ“¥ LTV ì˜ˆì¸¡ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
        data=pdf_buffer,
        file_name="ltv_report.pdf",
        mime="application/pdf"
    )


    st.markdown("### ê³ ê° ë§ì¶¤ ì¶”ì²œ")

    if "ì—°ë ¹ëŒ€" in df_with_pred.columns and "ê±°ì£¼ ì§€ì—­" in df_with_pred.columns:
        selected_age = st.selectbox("ì—°ë ¹ëŒ€ ì„ íƒ", df_with_pred["ì—°ë ¹ëŒ€"].unique())
        selected_region = st.selectbox("ê±°ì£¼ ì§€ì—­ ì„ íƒ", df_with_pred["ê±°ì£¼ ì§€ì—­"].unique())

        recommended = df_with_pred[
            (df_with_pred["ì—°ë ¹ëŒ€"] == selected_age) &
            (df_with_pred["ê±°ì£¼ ì§€ì—­"] == selected_region)
        ].sort_values("ì˜ˆì¸¡ LTV", ascending=False).head(5)

        st.markdown(f"**ì¶”ì²œ ê³ ê° TOP 5 (ì—°ë ¹ëŒ€: {selected_age}, ì§€ì—­: {selected_region})**")
        st.dataframe(recommended[["ì—°ë ¹ëŒ€", "ê±°ì£¼ ì§€ì—­", "ì˜ˆì¸¡ LTV"]])
    else:
        st.warning("ì—°ë ¹ëŒ€ ë˜ëŠ” ê±°ì£¼ ì§€ì—­ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")


    # ğŸ“Œ ì›ë³¸ ë°ì´í„° í™•ì¸
    st.markdown("###  ì›ë³¸ ë°ì´í„° í™•ì¸")
    with st.expander(" ì›ë³¸ ë°ì´í„° í™•ì¸"):
        tab1, tab2, tab3 = st.tabs(["ë”œëŸ¬ ìƒë‹´ ë¦¬ìŠ¤íŠ¸", "êµ­ë‚´ íŒë§¤ ê³ ê°ë°ì´í„°", "í•´ì™¸ íŒë§¤ ê³ ê°ë°ì´í„°"])

        with tab1:
            st.dataframe(df_list, use_container_width=True, hide_index=True)

        with tab2:
            # ì„ì˜ ì¬ê³  ë°ì´í„° ìƒì„± ë˜ëŠ” df_customer ì‚¬ìš©
            df_inv = df_customer.copy()
            st.dataframe(df_inv, use_container_width=True, hide_index=True)

        with tab3:
            # ì„ì˜ ê³µì¥ ë°ì´í„° ìƒì„± ë˜ëŠ” df_export ì‚¬ìš©
            df_plant = df_export.copy()
            st.dataframe(df_plant, use_container_width=True, hide_index=True)